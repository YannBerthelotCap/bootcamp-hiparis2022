{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <a>\n",
    "    <img src=\"./figures/logo-hi-paris-retina.png\" alt=\"Logo\" width=\"280\" height=\"180\">\n",
    "  </a>\n",
    "\n",
    "  <h3 align=\"center\">Data Science Bootcamp</h3>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors : Yann Berthelot, Florian Bettini, Laure-Am√©lie Colin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning\n",
    "======\n",
    "\n",
    "#### How can it be problematic for our analyst to use the dataset as is, without cleaning? \n",
    "\n",
    "#### WHAT IS DATA CLEANING:\n",
    "The purpose of this step is to normalize the data to facilitate its manipulation during the analysis.\n",
    "Several operations are possible: modify or delete data that are incorrect, incomplete, irrelevant, corrupted, duplicated or badly formatted\n",
    "\n",
    "### Why is this important? \n",
    "- Correct duplicate or misfiled data. \n",
    "- Correct errors in manual data entry. \n",
    "- Wrong data can affect the results and their accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective of this lab\n",
    "======\n",
    "\n",
    "Clean the fires datasets in order to obtain a quality dataset, without errors, duplicates, irrelevant values... ready to be analyzed\n",
    "\n",
    "### Data Path\n",
    "\n",
    "`./data/` is the path that contains all data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <a>\n",
    "    <img src=\"./figures/UpToYou.png\" alt=\"Logo\" width=\"200\" height=\"280\">\n",
    "  </a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from utils import check_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks = {True:\"OK\", False: \"NOK\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Preparation of the fires dataset</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw dataset is located in `./data/fires/fires.csv`\n",
    "\n",
    "This table includes wildfire data for the period of 2011-2015 compiled from US federal, state, and local reporting systems.\n",
    "\n",
    "Columns are :\n",
    "* `FOD_ID` = Global unique identifier.\n",
    "* `FIRE_SIZE` = Estimate of acres within the final perimeter of the fire.\n",
    "* `FIRESIZECLASS` = Code for fire size based on the number of acres within the final fire perimeter expenditures (A=greater than 0 but less than or equal to 0.25 acres, B=0.26-9.9 acres, C=10.0-99.9 acres, D=100-299 acres, E=300 to 999 acres, F=1000 to 4999 acres, and G=5000+ acres).\n",
    "* `FIRE_NAME` = Name of the incident, from the fire report (primary) or ICS-209 report (secondary).\n",
    "* `FIRE_YEAR` = Calendar year in which the fire was discovered or confirmed to exist.\n",
    "* `DISCOVERY_DATE` = Date on which the fire was discovered or confirmed to exist (Julian format)\n",
    "* `DISCOVERY_TIME` = Time of day that the fire was discovered or confirmed to exist.\n",
    "* `CONT_DATE` = Date on which the fire was declared contained or otherwise controlled (Julian format)\n",
    "* `CONT_TIME` = Time of day that the fire was declared contained or otherwise controlled (hhmm where hh=hour, mm=minutes).\n",
    "* `LATITUDE` = Latitude (NAD83) for point location of the fire (decimal degrees).\n",
    "* `LONGITUDE` = Longitude (NAD83) for point location of the fire (decimal degrees).\n",
    "* `STATE` = Two-letter alphabetic code for the state in which the fire burned (or originated), based on the nominal designation in the fire report.\n",
    "* `CAUSE_CODE` = Code for the cause of the fire.\n",
    "* `CAUSE_DESCR` = Description of the cause of the fire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datetime(x: pd.Series, opt: str) -> datetime:\n",
    "    '''\n",
    "    Create a datetime column for a DataFrame, based on dates and times. \n",
    "\n",
    "    Input:\n",
    "    x (pd.Series): row of the input DataFrame\n",
    "    opt (str): options for the columns name. Either \"DISCOVERY\" or \"CONT\".\n",
    "\n",
    "    Output:\n",
    "    (datetime): output datetime\n",
    "    '''\n",
    "    if (not np.isnan(x[opt + \"_TIME\"])) & (not pd.isnull(x[opt + \"_DATE\"])):\n",
    "        t = str(int(x[opt + \"_TIME\"])).rjust(4,\"0\")\n",
    "        d = x[opt + \"_DATE\"].strftime(\"%Y-%m-%d\")\n",
    "        dt = datetime.strptime(f\"{d} {t[:2]}:{t[2:]}\", \"%Y-%m-%d %H:%M\")\n",
    "        return dt\n",
    "\n",
    "def cleaning_fires(fires: pd.DataFrame, cols:list) -> pd.DataFrame:\n",
    "    '''\n",
    "    Clean the input dataframe, by converting dates and selecting columns\n",
    "\n",
    "    Input:\n",
    "    fires (pd.DataFrame): input DataFrame\n",
    "    cols (list): list of columns to keep\n",
    "\n",
    "    Output:\n",
    "    (pd.DataFrame): cleaned DataFrame\n",
    "    '''\n",
    "    # select useful columns\n",
    "    fires = fires.loc[:,cols]\n",
    "\n",
    "    # convert dates from Julian to Gregorian format\n",
    "    for c in [\"DISCOVERY_DATE\", \"CONT_DATE\"]:\n",
    "        fires[c] = pd.to_datetime(fires[c] - pd.Timestamp(0).to_julian_date(), unit='D')\n",
    "\n",
    "    # convert time if available\n",
    "    for option in [\"DISCOVERY\", \"CONT\"]:\n",
    "        fires[option + \"_TIME\"] = fires.apply(lambda x: convert_datetime(x, option), axis=1)\n",
    "\n",
    "    fires[\"DURATION\"] = (fires[\"CONT_TIME\"] - fires[\"DISCOVERY_TIME\"]).dt.total_seconds()\n",
    "    \n",
    "    return fires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check duplicates: OK\n"
     ]
    }
   ],
   "source": [
    "cols = [\n",
    "    'FOD_ID', 'FIRE_YEAR', 'DISCOVERY_DATE', 'DISCOVERY_TIME',\n",
    "    'CONT_DATE', 'CONT_TIME', 'FIRE_SIZE', 'FIRE_SIZE_CLASS',\n",
    "    'LATITUDE', 'LONGITUDE', 'STATE', 'CAUSE_CODE', 'CAUSE_DESCR'\n",
    "]\n",
    "\n",
    "# cleaning and feature engineering\n",
    "fires = pd.read_csv(\"./data/1_raw/fires/fires.csv\")\n",
    "fires = cleaning_fires(fires, cols)\n",
    "\n",
    "# check duplicate values\n",
    "c = checks.get(check_duplicates(fires, [\"FOD_ID\"]), False)\n",
    "print(f\"Check duplicates: {c}\")\n",
    "\n",
    "# save to csv\n",
    "fires.to_csv(\"./data/2_clean/fires.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take Away\n",
    "- Edit variable types / formats\n",
    "- Identify duplicates\n",
    "- Delete columns with many missing values\n",
    "- Use common sense and keep only relevant variables\n",
    "- Observe the distribution of values of a variable\n",
    "- Visual representations are useful to understand how a variable works\n",
    "\n",
    "### Pitfalls to avoid\n",
    "- Automatically delete a duplicate: understand why the duplicate appeared\n",
    "- Automatically delete all rows with missing values and lose information. Approximating some values allows you to keep information to meet an objective.\n",
    "- Automatically delete outliers: understand where they come from, are they errors or do they only represent extreme cases?\n",
    "- Retain variables that could be harmful to the ethics of a project (skin color, address...)\n",
    "\n",
    "### Go Further :\n",
    "- [The Ultimate Guide to Data Cleaning](https://towardsdatascience.com/the-ultimate-guide-to-data-cleaning-3969843991d4)\n",
    "- [Learn Data Cleaning Tutorials | Kaggle](https://www.kaggle.com/learn/data-cleaning)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f17db48aa853750bfee38181acc93506773951f4f6f179b65dfa4e5104417bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

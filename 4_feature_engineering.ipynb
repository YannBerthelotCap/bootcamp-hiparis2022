{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <a>\n",
    "    <img src=\"./figures/logo-hi-paris-retina.png\" alt=\"Logo\" width=\"280\" height=\"180\">\n",
    "  </a>\n",
    "\n",
    "  <h3 align=\"center\">Data Science Bootcamp</h3>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors : Yann Berthelot, Florian Bettini, Laure-Am√©lie Colin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we briefly recall some machine learning basics, and we are interested in a problem of building a regression model using machine learning algorithms.\n",
    "\n",
    "## What is a machine learning model:\n",
    "\n",
    "The Building a machine learning model can be summed up in finding a link function $f$\n",
    " ($Y=f(X) + \\epsilon$) which is most often the\n",
    "result of error minimization : <p style=\"text-align: center;\">$\\sum_i E(Y_i,f(X_i))$</p> where\n",
    "$(X_i,Y_i)$ is a list of pairs (features, target).\n",
    "\n",
    "**Objective:** \n",
    "- Train the model from a dataset and assess its ability to generalize on unseen data\n",
    "- Understand the explanatory factors of our target\n",
    "    \n",
    "**Method:**\n",
    "- Separate the target variable from the features\n",
    "- separate the data into three samples (train / validation / test)\n",
    "- train the model (on the train set) and evaluate its performance (on the test set).\n",
    "\n",
    "\n",
    "## Feature Engineering\n",
    "Feature engineering is the process by which knowledge of data is used to construct explanatory variables, features, that can be used to train a predictive model. Engineering and selecting the correct features for a model will not only significantly improve its predictive power, but will also offer the flexibility to use less complex models that are faster to run and more easily understood.\n",
    "\n",
    "### Feature Engineering from Datetime\n",
    "The timestamp in itself is not a useful feature, but we can extract from it some features. Ex: day of the week.\n",
    "\n",
    "### Feature Engineering from transformation \n",
    "Feature transformations can include aggregating, combining transforming attributes to create new features. Useful and relevant features will depend on the problem at hand but averages, sums, log or ratios can better expose trends to a model.\n",
    "\n",
    "We can also transform a numerical feature into a categorical feature by cutting it into classes. This can be interesting to avoid the impact of outliers or to reduce the variance of the output variable.\n",
    "\n",
    "##### Example: \n",
    "\n",
    "```python\n",
    "# log transformation\n",
    "data['var_transformed'] = data['var'].apply(np.log)\n",
    "\n",
    "# polynomial transformation\n",
    "data['var_transformed'] = data['var']**2\n",
    "```\n",
    "\n",
    "### Data Encoding\n",
    "Some algorithms can work with categorical data directly. This means that categorical data must be converted to a numerical form. \n",
    "To Convert Categorical Data to Numerical Data, this involves two steps :\n",
    "\n",
    "- Integer  (ordinal or cardinal)\n",
    "- One-Hot Encoding\n",
    "\n",
    "##### Example:\n",
    "Use [pd.get_dummies()](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) for OneHotEncoding\n",
    "\n",
    "```python\n",
    "# list of columns to encode using One-Hot-Encoding\n",
    "columns_to_encode = [\"var1\", \"var2\"]\n",
    "\n",
    "# encode those columns\n",
    "encoded_data = pd.get_dummies(data[columns_to_encode], columns=columns_to_encode)\n",
    "\n",
    "# add encoded columns to the data\n",
    "data = pd.concat([data, encoded_data], axis=1)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective of this lab\n",
    "======\n",
    "\n",
    "Use feature engineering to add new relevant features for your predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <a>\n",
    "    <img src=\"./figures/UpToYou.png\" alt=\"Logo\" width=\"200\" height=\"280\">\n",
    "  </a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Cleaning, Feature Engineering and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_external_data(external_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Compute new features based on the original features from the external_data dataset.\n",
    "\n",
    "    Input:\n",
    "    external_data (pd.DataFrame): input DataFrame\n",
    "\n",
    "    Output:\n",
    "    (pd.DataFrame): DataFrame with additional features\n",
    "    '''\n",
    "    external_data = external_data.groupby([\"STATE_CODE\", \"Date\"]).agg({\n",
    "        \"tmax\":[\"mean\", \"max\", \"min\"],\n",
    "        \"tmin\":[\"mean\", \"max\", \"min\"],\n",
    "        \"prcp\":[\"mean\", \"max\", \"min\"],\n",
    "        \"Median Age\":\"mean\",\n",
    "        \"Total Population\": \"mean\",\n",
    "        \"Average Household Size\": \"mean\"\n",
    "    }).reset_index()\n",
    "    kpis = [\n",
    "        \"tmax_mean\", \"tmax_max\", \"tmax_min\", \"tmin_mean\",\n",
    "        \"tmin_max\", \"tmin_min\", \"prcp_mean\", \"prcp_max\",\n",
    "        \"prcp_min\", \"Median Age_mean\", \"Total Population_mean\",\n",
    "        \"Average Household Size_mean\"\n",
    "    ]\n",
    "    external_data.columns = [\"STATE_CODE\", \"Date\", *kpis]\n",
    "\n",
    "    external_data[\"delta_t\"] = external_data[\"tmax_mean\"] - external_data[\"tmin_mean\"]\n",
    "\n",
    "    return external_data\n",
    "\n",
    "\n",
    "def feature_engineering_fires(fires: pd.DataFrame, fires_days: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Compute new features based on the original features from the fires dataset.\n",
    "\n",
    "    Input:\n",
    "    external_data (pd.DataFrame): input DataFrame\n",
    "\n",
    "    Output:\n",
    "    (pd.DataFrame): DataFrame with additional features\n",
    "    '''\n",
    "    # count the number of fire per day and state\n",
    "    fires_count = fires.groupby([\"DISCOVERY_DATE\", \"STATE\"]).agg({\"FOD_ID\":\"count\"}).reset_index()\n",
    "    fires_count.columns = [\"DISCOVERY_DATE\", \"STATE\", \"FIRE_COUNT\"]\n",
    "    combinations = fires_days[[\"DISCOVERY_DATE\", \"STATE\"]].copy()\n",
    "    fires_count = pd.merge(combinations, fires_count, how=\"left\", on=[\"DISCOVERY_DATE\", \"STATE\"])\n",
    "    fires_count[\"FIRE_COUNT\"] = fires_count[\"FIRE_COUNT\"].fillna(0).astype(\"int\")\n",
    "\n",
    "    # number of fires at t - 1 year, on a 1 month window, 1 week window and 1 day window\n",
    "    fires_count[\"FIRE_COUNT_Y1_M1\"] = fires_count.groupby([\"STATE\"])[[\"FIRE_COUNT\"]].transform(lambda x: x.shift(365).rolling(30).sum())\n",
    "    fires_count[\"FIRE_COUNT_Y1_W1\"] = fires_count.groupby([\"STATE\"])[[\"FIRE_COUNT\"]].transform(lambda x: x.shift(365).rolling(7).sum())\n",
    "    fires_count[\"FIRE_COUNT_Y1_D1\"] = fires_count.groupby([\"STATE\"])[[\"FIRE_COUNT\"]].transform(lambda x: x.shift(365))\n",
    "    return fires_count\n",
    "\n",
    "\n",
    "def feature_engineering_all(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Encode categorical variables and fill na values\n",
    "    '''\n",
    "    # add dates\n",
    "    df[\"DISCOVERY_DOW\"] = df[\"DISCOVERY_DATE\"].dt.dayofweek\n",
    "    df[\"DISCOVERY_MONTH\"] = df[\"DISCOVERY_DATE\"].dt.month\n",
    "    df[\"DISCOVERY_DAY\"] = df[\"DISCOVERY_DATE\"].dt.day\n",
    "    # drop unused columns\n",
    "    df.drop(columns=[\"Date\", \"STATE_CODE\", \"FIRE_COUNT\"], inplace=True)\n",
    "    # fillna kpis from external data\n",
    "    cols_fillna = [\n",
    "        \"tmax_mean\", \"tmax_max\", \"tmax_min\", \"tmin_mean\",\n",
    "        \"tmin_max\", \"tmin_min\", \"prcp_mean\",\n",
    "        \"prcp_max\", \"prcp_min\", \"delta_t\",\n",
    "        \"Median Age_mean\", \"Total Population_mean\",\n",
    "        \"Average Household Size_mean\", \"FIRE_COUNT_Y1_M1\",\n",
    "        \"FIRE_COUNT_Y1_W1\", \"FIRE_COUNT_Y1_D1\"\n",
    "    ]\n",
    "    for c in cols_fillna:\n",
    "        df[c] = df[c].fillna(df[c].mean())\n",
    "\n",
    "    # encode state\n",
    "    data_cat = pd.get_dummies(df[\"STATE\"])\n",
    "    df = pd.concat([df, data_cat], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set\n",
    "fires_days = pd.read_csv(\"./data/1_raw/fires/fires_days_train.csv\", parse_dates=[\"DISCOVERY_DATE\"])\n",
    "\n",
    "# external_data\n",
    "external_data = pd.read_csv(\"./data/2_clean/external_data.csv\", parse_dates=[\"Date\"])\n",
    "external_data = feature_engineering_external_data(external_data)\n",
    "\n",
    "# fires data\n",
    "fires = pd.read_csv(\"./data/2_clean/fires.csv\", parse_dates=[\"DISCOVERY_DATE\"])\n",
    "fires_count = feature_engineering_fires(fires, fires_days)\n",
    "\n",
    "# merge\n",
    "fires_days = pd.merge(fires_days, external_data, how=\"left\", left_on=[\"STATE\", \"DISCOVERY_DATE\"], right_on=[\"STATE_CODE\", \"Date\"])\n",
    "fires_days = pd.merge(fires_days, fires_count, how=\"left\", on=[\"STATE\", \"DISCOVERY_DATE\"])\n",
    "\n",
    "# cleaning and encoding\n",
    "fires_days = feature_engineering_all(fires_days)\n",
    "\n",
    "# save to csv format\n",
    "fires_days.to_csv(\"./data/3_input_model/input_model.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f17db48aa853750bfee38181acc93506773951f4f6f179b65dfa4e5104417bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

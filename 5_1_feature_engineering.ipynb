{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import check_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Cleaning, Feature Engineering and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(fires: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Clean the dataset.\n",
    "\n",
    "    Input:\n",
    "    fires (pd.DataFrame): input DataFrame\n",
    "\n",
    "    Output:\n",
    "    (pd.DataFrame): cleaned DataFrame\n",
    "    '''\n",
    "    # TODO remove DURATION, FIRE_CODE, FIRE_NAME, FIPS_CODE, COUNTY, FIPS_NAME\n",
    "    drop_cols = [\"FIRE_CODE\", \"FIRE_NAME\", \"DISCOVERY_TIME\", \"CONT_DATE\", \"CONT_TIME\", \"FIRE_SIZE_CLASS\", \"COUNTY\", \"FIPS_CODE\", \"FIPS_NAME\", \"CLOSEST_CITY\", \"State\", \"STATE_CODE\", \"DURATION\", \"CAUSE_DESCR\"]\n",
    "    fires = fires.drop(columns=drop_cols)\n",
    "\n",
    "    # na values for temperatures\n",
    "    for c in [\"tmax\", \"tmin\", \"prcp\", \"Total Population\", \"Average Household Size\", \"Median Age\"]:\n",
    "        fires[c] = fires[c].fillna(fires[c].mean())\n",
    "        \n",
    "    return fires\n",
    "\n",
    "\n",
    "def feature_engineering(fires: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Compute new features based on the original features from the Fires dataset.\n",
    "\n",
    "    Input:\n",
    "    fires (pd.DataFrame): input DataFrame\n",
    "\n",
    "    Output:\n",
    "    (pd.DataFrame):  DataFrame with additional features\n",
    "    '''\n",
    "    # dates\n",
    "    fires[\"DISCOVERY_DOW\"] = fires[\"DISCOVERY_DATE\"].dt.dayofweek\n",
    "    fires[\"DISCOVERY_MONTH\"] = fires[\"DISCOVERY_DATE\"].dt.month\n",
    "    fires[\"DISCOVERY_DAY\"] = fires[\"DISCOVERY_DATE\"].dt.day\n",
    "    # fires = fires.drop(columns=[\"DISCOVERY_DATE\"])\n",
    "\n",
    "    return fires\n",
    "\n",
    "\n",
    "def encoding(fires: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Encode categorical variables\n",
    "\n",
    "    Input:\n",
    "    fires (pd.DataFrame): input DataFrame\n",
    "\n",
    "    Output:\n",
    "    (pd.DataFrame):  DataFrame with encoded categorical variables\n",
    "    '''\n",
    "    # encode states\n",
    "    data_cat = pd.get_dummies(fires[\"STATE\"])\n",
    "    fires = pd.concat([fires, data_cat], axis=1)\n",
    "    fires = fires.drop(columns=[\"STATE\"])\n",
    "\n",
    "    return fires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fbettini\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3258: DtypeWarning: Columns (1,17) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# read file and process it\n",
    "fires = pd.read_csv(\"./data/3_merge/merged_data_haversine.csv\", parse_dates=[\"DISCOVERY_DATE\", \"CONT_DATE\"])\n",
    "fires = cleaning(fires)\n",
    "fires = feature_engineering(fires)\n",
    "fires = encoding(fires)\n",
    "fires.to_csv(\"./data/4_input_model/model_1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f17db48aa853750bfee38181acc93506773951f4f6f179b65dfa4e5104417bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
